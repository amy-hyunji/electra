{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "electra.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNK9QVepA5Q6g0qeqS4b+yr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amy-hyunji/electra/blob/master/fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QU7bFD6iJbd",
        "colab_type": "code",
        "outputId": "29205a80-d2f8-41b4-e567-5e5cfa2d1bdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import csv\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://'+os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is ', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credential to TPU\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "TPU address is  grpc://10.98.184.90:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 3336342074931109970),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 10609587352834502578),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 17135698840319588645),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 18229034982624243744),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 5656394919899334314),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 1903466732757843958),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 17744601432996319326),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 8410569030169933049),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 16264202919638258061),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16648009403097233747),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 12690615845676437534)]\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9Huux84jfsj",
        "colab_type": "code",
        "outputId": "544c3708-0272-4a0a-d71a-6157be941bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!test -d electra || git clone https://github.com/amy-hyunji/electra.git electra\n",
        "if not 'electra' in sys.path:\n",
        "  sys.path += ['electra']\n",
        "print(os.listdir('electra'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['build_openwebtext_pretraining_dataset.py', '.git', 'README.md', 'model', 'configure_finetuning.py', 'util', 'CONTRIBUTING.md', 'LICENSE', 'run_pretraining.py', 'run_finetuning.py', 'finetune', 'pretrain', 'build_pretraining_dataset.py', 'configure_pretraining.py']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5bA8W4HlTRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries in run_finetuning.py\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import collections\n",
        "import json\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "import configure_finetuning\n",
        "from finetune import preprocessing, task_builder\n",
        "from model import modeling, optimization\n",
        "from util import training_utils, utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y826koHHBn6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FinetuningModel(object):\n",
        "  \"\"\"Finetuning model with support for multi-task training\"\"\"\n",
        "\n",
        "  def __init__(self, config: configure_finetuning.FinetuningConfig, tasks, is_training, features, num_train_steps):\n",
        "\n",
        "    # Create a shared transformer encoder\n",
        "    bert_config = training_utils.get_bert_config(config) # get model hyperparameters based on a pretraining/finetuning config\n",
        "    self.bert_config = bert_config\n",
        "    if config.debug: #..?\n",
        "      bert_config.num_hidden_layers = 3\n",
        "      bert_config.hidden_size = 144\n",
        "      bert_config.intermediate_size = 144*4\n",
        "      bert_config.num_attention_heads = 4\n",
        "    assert config.max_seq_length <= bert_config.max_position_embeddings\n",
        "    bert_model = modeling.BertModel(\n",
        "        bert_config = bert_config,\n",
        "        is_training = is_training,\n",
        "        input_ids = features['input_ids'],\n",
        "        input_mask = features['input_mask'],\n",
        "        token_type_ids = features['segment_ids'],\n",
        "        use_one_hot_embeddings = config.use_tpu,\n",
        "        embedding_size = config.embedding_size\n",
        "    )\n",
        "    percent_done = (tf.cast(tf.train.get_or_create_global_step(), tf.float32) / tf.cast(num_train_steps, tf.float32)\n",
        "\n",
        "    # add specific tasks - CHECK!!\n",
        "    self.outputs = {\"task_id\": features['task_id']}\n",
        "    losses = []\n",
        "    for task in tasks:\n",
        "      with tf.variable_scope(\"task_specific/\" + task.name):\n",
        "        task_losses, task_outputs = task.get_prediction_module(bert_model, features, is_training, percent_done)\n",
        "        losses.append(task_losses)\n",
        "        self.outputs[task.name] = task_outputs\n",
        "    self.loss = tf.reduce_sum(tf.stack(losses, -1) * tf.one_hot(features['task_id'], len(config.task_names)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEKDtGM2zeC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Fine-tunes a model on a supervised task\n",
        "Explains how to train/eval when fine-tuning\n",
        "\"\"\"\n",
        "\n",
        "def model_fn_builder(config: configure_finetuning.FinetuningConfig, tasks, num_train_steps, pretraining_config=None):\n",
        "  \"\"\"Returns 'model_fn' closure for TPUEstimator\"\"\"\n",
        "  def model_fn(features, labels, mode, params):\n",
        "    \"\"\"the 'model_fn' for TPUEstimator\"\"\"\n",
        "    utils.log(\"Building model...\")\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    model = FinetuningModel(config, tasks, is_training, features, num_train_steps)\n",
        "\n",
        "    # load pretrained weights from checkpoint\n",
        "    init_checkpoint = config.init_checkpoint\n",
        "    if pretraining_config is not None:\n",
        "      init_checkpoint = tf.train.latet_checkpoint(pretraining_config.model_dir)\n",
        "      utils.log('Using checkpoint ', init_checkpoint)\n",
        "    tvars = tf.trainable_variables()\n",
        "    \n",
        "    # scaffold_fn : something for TPU\n",
        "    scaffold_fn = None\n",
        "    if init_checkpoint:\n",
        "      assignment_map, _ = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "      if config.use_tpu:\n",
        "        def tpu_scaffold():\n",
        "          tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "          return tf.train.Scaffold()\n",
        "        scaffold_fn = tpu_scaffold\n",
        "      else:\n",
        "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "    \n",
        "    # Build model for training or prediction\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      train_op = optimization.create_optimizer(\n",
        "          model.loss, config.learning_rate, num_train_steps, \n",
        "          weight_decay_rate = config.weight_decay_rate,\n",
        "          use_tpu = config.use_tpu,\n",
        "          warmup_proportion = config.warmup_proportion,\n",
        "          layerwise_lr_decay_power = config.layerwise_lr_decay,\n",
        "          n_transformer_layers = model.bert_config.num_hidden_layers # use bert hidden layer.. for embedding??\n",
        "      )\n",
        "      output_spec = tf.estimator.tpu.TPUEstimatorSpec(\n",
        "          mode = mode,\n",
        "          loss = model.loss,\n",
        "          train_op = train_op,  # optimizer when training\n",
        "          scaffold_fn = scaffold_fn,\n",
        "          training_hooks = [training_utils.ETAHook(\n",
        "              {} if config.use_tpu else dict(loss=mdoel.loss),\n",
        "              num_train_steps, config.iterations_per_loop, config.use_tpu, 10\n",
        "          )])\n",
        "    else:\n",
        "      assert mode == tf.estimator.ModeKeys.PREDICT\n",
        "      output_spec = tf.estimator.tpu.TPUEstimatorSpec(\n",
        "          mode = mode,\n",
        "          predictions = utils.flatten_dict(model.outputs),\n",
        "          scaffold_fn = scaffold_fn\n",
        "      )\n",
        "    utils.log(\"Building Complete\")\n",
        "    return output_spec\n",
        "\n",
        "  return model_fn\n",
        "\n",
        "      \n",
        "\n",
        "class ModelRunner(object):\n",
        "  def __init__(self, config: configure_finetuning.FinetuningConfig, tasks, pretraining_config=None):\n",
        "    self._config = config\n",
        "    self._tasks = tasks\n",
        "    self._preprocessor = preprocessing.Preprocessor(config, self._tasks) ## CHECK!!\n",
        "\n",
        "    # check if it is okay with GPU\n",
        "    is_per_host = tf.estimator.tpu.InputPipelineConfig.PER_HOST_V2\n",
        "    tpu_cluster_resolver = None\n",
        "    if config.use_tpu and config.tpu_name:\n",
        "      tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\n",
        "        config.tpu_name, zone=config.tpu_zone, project=config.gcp_project\n",
        "      )\n",
        "    tpu_config = tf.estimator.tpu.TPUConfig(\n",
        "        iterations_per_loop = config.iterations_per_loop,\n",
        "        num_shards = config.num_tpu_cores,\n",
        "        per_host_input_for_training = is_per_host,\n",
        "        tpu_job_name = config.tpu_job_name\n",
        "    )\n",
        "    run_config = tf.estimator.tpu.RunConfig(\n",
        "        cluster = tpu_cluster_resolver,\n",
        "        model_dir = config.model_dir,\n",
        "        save_checkpoints_steps = config.save_checkpoints_steps,\n",
        "        save_checkpoints_secs = None,\n",
        "        tpu_config = tpu_config\n",
        "    )\n",
        "\n",
        "    if self._config.do_train:\n",
        "      (self._train_input_fn, self.train_steps) = self._preprocessor.prepare_train() # check!\n",
        "    else:\n",
        "      self._train_input_fn, self.train_steps = None, 0\n",
        "\n",
        "    # defined on top\n",
        "    model_fn = model_fn_builder(\n",
        "        config = config, \n",
        "        tasks = self._tasks,\n",
        "        num_train_steps = self.train_steps,\n",
        "        pretraining_config = pretraining_config\n",
        "    )\n",
        "    # tf.estimator.tpu.TPUEstimator is also available to use in GPU and CPU\n",
        "    self._estimator = tf.estimator.tpu.TPUEstimator(\n",
        "        use_tpu = config.use_tpu,\n",
        "        model_fn = model_fn, \n",
        "        config = run_config,\n",
        "        train_batch_size = config.train_batch_size,\n",
        "        eval_batch_size = config.eval_batch_size,\n",
        "        predict_batch_size = config.predict_batch_size\n",
        "    )\n",
        "\n",
        "    def train(self):\n",
        "      utils.log(\"Training for {:} steps\".format(self.train_steps))\n",
        "      self._estimator.train(input_fn = self._train_input_fn, max_steps = self.train_steps)\n",
        "\n",
        "    def evaluate(self):\n",
        "      return {task.name: self.evaluate_task(task) for task in self._tasks}\n",
        "\n",
        "    def evaluate_task(self, task, split=\"dev\", return_results=True):\n",
        "      \"\"\"Evaluate the current model\"\"\"\n",
        "      utils.log(\"Evaluating \", task.name)\n",
        "      eval_input_fn, _ = self._preprocessor.prepare_predict([task], split)\n",
        "      results = self._estimator.predict(input_fn = eval_input_fn, yield_single_examples = True)\n",
        "      scorer = task.get_scorer()\n",
        "      for r in results:\n",
        "        if r['task_id'] != len(self._tasks):\n",
        "          r = utils.nest_dict(r, self._config.task_names)\n",
        "          scorer.update(r[task.name])\n",
        "        if return_results:\n",
        "          utils.log(task.name + \": \"+scorer.results_str())\n",
        "          utils.log()\n",
        "          return dict(scorer.get_results())\n",
        "        else:\n",
        "          return scorer\n",
        "\n",
        "    # used when TESTing GLUE\n",
        "    def write_classification_outputs(self, tasks, trial, split):\n",
        "      \"\"\"write classification predictions to disk\"\"\"\n",
        "      utils.log(\"Writing out predictions for \", tasks, split)\n",
        "      predict_input_fn, _ = self._preprocessor.prepare_predict(tasks, split)\n",
        "      results = self._estimator.predict(input_fn = predict_input_fn, yield_single_example = True)\n",
        "\n",
        "      # task name -> eid -> model-logits\n",
        "      logits = collections.defaultdict(dict)\n",
        "      for r in results:\n",
        "        if r['task_id'] != len(self._tasks):\n",
        "          r = utils.nest_dict(r, self._config.task_names)\n",
        "          task_name = self._config.task_names[r['task_id']]\n",
        "          logits[task_name][r[task_name]['eid']] = (\n",
        "              r[task_name]['logits'] if 'logits' in r[task_name]\n",
        "              else r[task_name]['predictions']\n",
        "          )\n",
        "      for task_name in logits:\n",
        "        utils.log('Pickling predictions for {:} {:} examples ({:})'.format(len(logits[task_name], task_name, split)))\n",
        "        if trial <= self._config.n_writes_test:\n",
        "          utils.write_pickle(logits[task_name], self._config.test_predictions(task_name, split, trial))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XetAOyo-s3zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_results(config: configure_finetuning.FinetuningConfig, results):\n",
        "  \"\"\"Write evaluation metrics to disk\"\"\"\n",
        "  utils.log(\"Writing results to \", config.results_txt)\n",
        "  utils.mkdir(config.results_txt.rsplit(\"/\", 1)[0])\n",
        "  utils.write_pickle(results, config.results_pkl)\n",
        "  with tf.io.gfile.GFile(config.results_tzt, \"w\") as f:\n",
        "    results_str = \"\"\n",
        "    for train_results in results:\n",
        "      for task_name, task_results in trial_results.items():\n",
        "        if task_name == 'time' or task_name == \"global_step\":\n",
        "          continue\n",
        "        results_str += task_name + \": \"+\" - \".join([\"{:}: {:.2f}\".format(k, v) for k, v in task_results.items()]) + \"\\n\"\n",
        "    f.write(results_str)\n",
        "  utils.write_pickle(results, config.results_pkl)\n",
        "\n",
        "\"\"\"Run Finetuning\"\"\"\n",
        "def run_finetuning(config: configure_finetuning.FinetuningConfig):\n",
        "\n",
        "# setup for training\n",
        "results = []\n",
        "trial = 1\n",
        "heading_info = \"model: {:}, trial {:}/{:}\".format(\n",
        "    config.model_name, trial, config.num_trials\n",
        ")\n",
        "heading = lambda msg: utils.heading(msg+ \": \"+heading_info)\n",
        "\n",
        "# write down cofig\n",
        "heading(\"Config\")\n",
        "utils.log_config(config)\n",
        "generic_model_dir = config.generic_model_dir\n",
        "tasks = task_builder.get_tasks(config)\n",
        "\n",
        "# Train and Eval num_trials models with different random seeds\n",
        "while config.num_trials < 0 or trial <= config.num_trials:\n",
        "  config.model_dir = generic_model_dir + \"_\" + str(trial)\n",
        "  if config.do_train:\n",
        "    utils.rmkdir(config.model_dir)\n",
        "  \n",
        "  model_runner = ModelRunner(config, tasks)\n",
        "  if config.do_train:\n",
        "    heading(\"Start Training\")\n",
        "    model_runner.train()\n",
        "    utils.log()\n",
        "  if config.do_eval:\n",
        "    heading(\"Run dev set evaluation\")\n",
        "    results.append(model_runner.evaluate())\n",
        "    write_results(config, results)\n",
        "    if config.write_test_output and trial <= config.n_writes_test:\n",
        "      heading(\"Running on the test set and writing the predictions\")\n",
        "      for task in tasks:\n",
        "        # Currently only writing preds from GLUE and SQuAD 2.0 is supported\n",
        "        if task.name in ['cola', 'mrpc', 'mnli', 'sst', 'rte', 'qnli', 'qqp' 'sts']:\n",
        "          \"\"\"GLUE task\"\"\"\n",
        "          for split in task.get_test_splits():\n",
        "            model_runner.write_classification_outputs([task], trial, split)\n",
        "        elif task.name = 'squad':\n",
        "          \"\"\"SQUAD task\"\"\"\n",
        "          scorer = model.runner.evaluate_task(task, \"test\", False)\n",
        "          scorer.write_predictions()\n",
        "          preds = utils.load_json(config.qa_preds_file(\"squad\"))\n",
        "          null_odds = utils.load_json(config.qa_na_file('squad'))\n",
        "          for q, _ in preds.items():\n",
        "            if null_odds[q] > config.qa_na_threshold:\n",
        "              preds[q] = \"\" # check!\n",
        "          utils.write_json(preds, config.test_predictions(\n",
        "              task.name, \"test\", trial\n",
        "          ))\n",
        "        else:\n",
        "          utils.log(\"Skipping task\", task.name, \"- writing predictions is not supported for this task\")\n",
        "\n",
        "    if trial != config.num_trials and (not config.keep_all_models):\n",
        "      utils.rmrf(config.model_dir)\n",
        "    trial += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF0R3Yu8mVsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(data_dir, model_name, hparams):\n",
        "  if \".json\" in hparams:\n",
        "    hparams = utils.load_json(hparams)\n",
        "  else:\n",
        "    hparams = json.loads(hparams)\n",
        "  \n",
        "  tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "  run_finetuning(configure_finetuning.FinetuningConfig(\n",
        "      model_name, data_dir, **hparams\n",
        "  ))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}